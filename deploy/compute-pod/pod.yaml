apiVersion: "kubeflow.org/v1"
kind: PyTorchJob
metadata:
  name: compute-job  # Changed name to reflect it being a job
  namespace: distributed-system
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1  # Keep at least one master replica
      restartPolicy: OnFailure
      template:
        metadata:
          labels:
            app: compute-pod
        spec:
          containers:
            - name: pytorch
              image: compute-engine:latest  # Use your compute-engine image
              imagePullPolicy: IfNotPresent
              command: ["python", "train.py"]
              ports:
                - name: pytorch
                  containerPort: 8080
              env:
                - name: TASK_ID
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: MVCC_HOST
                  value: compute-node-svc # Correct service name for MVCC
                - name: MVCC_PORT
                  value: "8083"
              resources:
                requests:
                  memory: "512Mi"
                  cpu: "500m"
                limits:
                  memory: "1Gi"
                  cpu: "1000m"
    Worker:
      replicas: 2  # Adjust the number of worker replicas as needed
      restartPolicy: OnFailure
      template:
        metadata:
          labels:
            app: compute-pod
        spec:
          containers:
            - name: pytorch
              image: compute-engine:latest # Use your compute-engine image
              imagePullPolicy: IfNotPresent
              command: ["python", "train.py"]
              ports:
                - name: pytorch
                  containerPort: 8080
              env:
                - name: TASK_ID
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: MVCC_HOST
                  value: compute-node-svc # Correct service name for MVCC
                - name: MVCC_PORT
                  value: "8083"
              resources:
                requests:
                  memory: "512Mi"
                  cpu: "500m"
                limits:
                  memory: "1Gi"
                  cpu: "1000m"

            # Monitoring sidecar
            - name: monitor
              image: monitor:latest
              ports:
                - name: monitor
                  containerPort: 8081
              volumeMounts:
                - name: shared-memory
                  mountPath: /dev/shm
              resources:
                requests:
                  memory: "64Mi"
                  cpu: "100m"
                limits:
                  memory: "128Mi"
                  cpu: "200m"

            # Failure agent sidecar
            - name: failure-agent
              image: failure-agent:latest
              ports:
                - name: failure-agent
                  containerPort: 8082
              env:
                - name: FAILURE_SERVER_URL
                  value: http://failure-server:8092
              resources:
                requests:
                  memory: "64Mi"
                  cpu: "100m"
                limits:
                  memory: "128Mi"
                  cpu: "200m"

          volumes:
            - name: shared-memory
              emptyDir:
                medium: Memory